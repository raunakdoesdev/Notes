# Daily Log 7/7/17

- Did some sys admin tasks like changing passwords and setting up new users on BDD3 machine (wow there are a lot of users! we really need to get new machines setup ASAP)

## Karl's Training Rewrite
- I looked through Karl's training rewrite a third time today, and everything looks good, hopefully I'm not missing anything, though it is incredibly hard to read is code given how far he strays from standard pythonic style.

## Metadata Inference
- [ ]  I want to try out my metadata inference network on the car. Haven't yet gotten a chance to implement that yet.
- [ ] First should try some experiments with the actual networks I have trained (Look at the metadata inferred vs. the ground truth metadata)

## Stopping Behavior
- [ ] Run a validation dataset, on each epoch of a trained SqueezeNet model, and graph the standard deviation of the motor values. I wrote a [PyTorch forums post](https://discuss.pytorch.org/t/calculate-standard-deviation-of-output-of-network-over-many-samples/4706) about the best way to do this. If this shows that the stopping behavior builds up over epochs as we have seen, this is importaint information for our paper.
    
    #### Online Variance
    - After doing some research on Wikipedia, I found the following algorithm which is supposedly very accurate, and it's O(N) but it does have a single divide in the loop which may slow things down:
        ```python
        def online_variance(data):
            n = 0
            mean = M2 = 0.0
        
            for x in data:
                n += 1
                delta = x - mean
                mean += delta/n
                delta2 = x - mean
                M2 += delta*delta2
        
            return M2/(n -1)
        ```
    - [x] Code online variance algorithm to use PyTorch Tensors.
        ```python
        n = 0
        mean = torch.FloatTensor(1, 10).zero_().cuda()
        M2 = torch.FloatTensor(1, 10).zero_().cuda()
        
        # Add following to training loop
        n += 1
        x = output.chunk(2)[1].data[0]
        delta = x - mean
        mean += delta/n
        delta2 = x - mean
        M2 += delta*delta2

        print(M2/(n -1)) # Final variance
        ```


