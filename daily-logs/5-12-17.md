  # Daily Log 5/12/17
  ## Findings
  - Camera processing is taking a toal of about 0.14 seconds out of the 0.15 seconds it takes to run the network on an input image. Out of this conversion from numpy to PyTorch is taking about 0.10 seconds. If we could optimize this conversion it would allow us to run much larger networks on the TX2.
  ## TODOs
  ### Metadata Inference
  - [ ] Autograd isn't working since I am creating a new tensor based on values from squeezenet, same tensor should be going through the system. Post on PyTorch forums to see how you can create something to do this with backpropagation enabled.
  - [ ] Implement Transfer Learning with SqueezeNet
  ### NVIDIA
  - [x] Figure out what part of the camera processing is taking so long and report detailed timing statistics to Karl (my guess is conversion from numpy to pytorch tensor)
  - [x] Email Dustin to find out how to optimize input from ZED Depth Camera for PyTorch Implementation
  ### Qualcomm
  - [x] Email Karl about time sink through the Snapdragon Board
