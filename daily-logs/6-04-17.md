# Daily Log 06/04/17

## Summary of Work Done so Far

- Tested squeeze net on the car and got the following results:

> The network itself ran at 20 Hz compared to the 30 Hz at which our Z2Color network runs. When driving the network had a tendency to move slightly to the right while going forward, unless there was an obstacle in it's path at which point it would either maneuver around it or stop. It seemed to be able to distinguish drivable and non drivable terrain fairly well, as it would drive over a smooth dirt patch but not onto a grassy area. When put on the sidewalk many times it would move onto driveways or go off the road, but it would never run into anything or move onto any uneven terrain. In many cases it would stop in front of an obstacle or in front of grass and have no idea what it should do, this is behavior I noticed in the Z2Color model as well.

- Did some more work with metadata inference and got the following results:

> I tried training it with only the direct sidewalk driving and follow modes (these are the only easily distinguishable modes we have in our dataset), and it achieved comparable validation errors to the z2color network trained on the same dataset. The drive network it was using was also a network with much higher validation loss and was actually trained on the entire dataset not just drive and follow modes. I will be trying metadata inference with a fully converged SqueezeNet drive net and z2color drive network on this same data to see if I can match/exceed the performance of z2color on the same dataset using metadata inference. If I can achieve these results I'd like to talk to you about adapting our current metadata modes to be more distinguishable and optimized for the metadata inference task.

- Met with Qualcomm to get Board Update, details below:

> The meeting was kinda a waste of both my and Qualcomm's time. I had given them the board prior to the meeting per their request to fix it before m arrival. All they had done was run a flashing script that had failed, they didn't put in the effort to monitor if the script had run succesfully. We spent the entire time we had together hunting down various people around the office to fix my board and when I left it still wasn't fixed. However, they did promise to fix the board and send it back to me by Friday. It's Sunday now, but it doesn't matter when I get it, as long as it's not wasting my time.

## Immediate Task List

- [ ] Try training the networks on more spaced out frames and use more spaced out frames during inference as well.
- [ ] Try training the networks on a larger number of frames.
- [ ] Rather than convert the data every time the network is run during inference, try recyling the converted images and use them for the next iteration just shifted in time.

## Long Term Research Goals

- [ ] Beat Z2Color training accuracy on the same dataset by using a fully converged SqueezeNet Drive Network and a SqueezeNet Plan Network.
- [ ] Analyze differences in grund truth metadata and inferred metadata

## Cool Things to Try

- [ ] Make the transition to Google's TensorBoard for monitoring training progress. This will allow easy access to image data and a clear view of our network's performance. This is something that is dangerously lacking in our current training setup.
