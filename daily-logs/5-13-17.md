# Daily Log 5/13/17

## Tushar's SqueezeNet Replacement
- Am still getting really great results from Tushar's implementation of using SqueezeNet to replace Z2Color:
```
-rw-rw-r-- 1 tpankaj tpankaj 5.7M May  7 10:16 epoch_save_0.0.00485315997295
-rw-rw-r-- 1 tpankaj tpankaj 5.7M May  8 06:04 epoch_save_1.0.00458513229449
-rw-rw-r-- 1 tpankaj tpankaj 5.7M May  9 03:31 epoch_save_2.0.00445009451694
-rw-rw-r-- 1 tpankaj tpankaj 5.7M May 10 00:42 epoch_save_3.0.00427434084036
-rw-rw-r-- 1 tpankaj tpankaj 5.7M May 10 22:05 epoch_save_4.0.00413679074525
-rw-rw-r-- 1 tpankaj tpankaj 5.7M May 11 19:29 epoch_save_5.0.00404983706991
-rw-rw-r-- 1 tpankaj tpankaj 5.7M May 12 11:00 epoch_save_6.0.00399571756212
-rw-rw-r-- 1 tpankaj tpankaj 5.7M May 13 02:48 epoch_save_7.0.00391657557776
-rw-rw-r-- 1 tpankaj tpankaj 5.7M May 13 18:34 epoch_save_8.0.00387504257538
```
- [ ] Should test the best SqueezeNet  network on the car tommorow, hopefully we can observe some interesting performance.

## Dual Net Metadata Inference

Confirmed that my network wasn't training because the chain of autograd was being broken when I used the for loop to construct the expanded metadata network. After posting in the [PyTorch forum](https://discuss.pytorch.org/t/expand-output-of-network-chained-neural-nets/2931) I was adivised to look into the unsqueeze and expand methods in PyTorch. I took a look, and these have the exact functionality I need. (Thanks smth!)

- [x] Play around in iPython and try to get my input tensor to look like my output tensor using the above functions.
	* Got it working it's really simple! Never would have figured this out without the post on the forum, since the docs were kinda vague about the functions use. Code shown below.
		```python
		# This entire process doesn't break the autograd chain.
		from torch import *
		a = FloatTensor([0, 1, 2, 3, 4, 5])
		a = a.unsqueeze(0)  # add the batch size dimension
		a = a.unsqueeze(2)  # create singular dimension for expand
		a = a.expand(1, 6, 13) # expand each of the rows in the image
		a = a.unsqueeze(3)  # create second singular dimension for expand
		a = a.expand(1, 6, 13, 26)  # expand each of the columns in the image
		a.size() # Outputs: torch.Size([1, 6, 13, 26])
		```
- [ ] Reimplement dual net inference code (just need to change the handoff from one network to the other)

Honestly I'm amazed at the power and flexibility of PyTorch. In any other deep learning framework, something like this would be very difficult to achieve.

## Optimizing TX2 Performance
Sent the following email to Dustin yesterday, but haven't gotten a response yet (understandable it's the weekend). Will do some more research on optimizing ZED input for PyTorch. 
>Hi Dustin,
>
>Thanks again for helping me out with setting up PyTorch on the NVIDIA TX2. We now have inference running on the TX2 with input from the ZED Depth Camera. However processing the images from the ZED camera is slowing down our inference.
>
>Our code right now gets the most updated ROS images from the ZED camera and converts them to numpy arrays using CVBridge imgmsg_to_cv2. I then took these arrays and converted them to PyTorch tensors through the torch.from_numpy() method. Unfortunately, this method is fairly slow (especially the numpy to PyTorch conversion).
>
>Since you have experience running PyTorch and using the ZED Depth Camera on the NVIDIA TX2 board I was hoping you could give me some advice on how to efficiently use the ZED data for PyTorch inference efficiently. Karl mentioned that in the past you haven't use ROS to get the ZED images, and have a better solution instead. 
>
>Any help would be appreciated.
>
>Thank You,  
>Sauhaarda Chowdhuri
